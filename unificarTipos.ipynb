{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os DataFrames\n",
    "df2013 = pd.read_excel('./BaseLimpo/2013_coleta_tipos_residuos.xlsx')\n",
    "df2014 = pd.read_excel('./BaseLimpo/2014_coleta_tipos_residuos.xlsx')\n",
    "df2015 = pd.read_excel('./BaseLimpo/2015_coleta_tipos_residuos.xlsx')\n",
    "df2016 = pd.read_excel('./BaseLimpo/2016_coleta_tipos_residuos.xlsx')\n",
    "df2017 = pd.read_excel('./BaseLimpo/2017_coleta_tipos_residuos.xlsx')\n",
    "df2018 = pd.read_excel('./BaseLimpo/2018_coleta_tipos_residuos.xlsx')\n",
    "df2019 = pd.read_excel('./BaseLimpo/2019_coleta_tipos_residuos.xlsx')\n",
    "df2020 = pd.read_excel('./BaseLimpo/2020_coleta_tipos_residuos.xlsx')\n",
    "df2021 = pd.read_excel('./BaseLimpo/2021_coleta_tipos_residuos.xlsx')\n",
    "df2023 = pd.read_excel('./BaseLimpo/2023_coleta_tipos_residuos.xlsx')\n",
    "df2024 = pd.read_excel('./BaseLimpo/2024_coleta_tipos_residuos.xlsx')\n",
    "\n",
    "\n",
    "# Criar uma lista com os DataFrames, excluindo o de 2022\n",
    "dfs = [df2013, df2014, df2015, df2016, df2017, df2018, df2019, df2020, df2021]\n",
    "\n",
    "# Inicializar o DataFrame final com o primeiro DataFrame (df2013)\n",
    "df = df2013[['tipo_residuo', 'total_2013']]\n",
    "\n",
    "\n",
    "for i,x in enumerate(dfs[1:], start=2014):\n",
    "    coluna_nome = f'total_{i}'\n",
    "            \n",
    "    # Realizar o merge (junção) com base na coluna 'tipo_residuo\n",
    "    df = pd.merge(df, x[['tipo_residuo', coluna_nome]], on='tipo_residuo', how='outer')\n",
    "    \n",
    "\n",
    "dfs2 = [df2023, df2024]\n",
    "\n",
    "for i,y in enumerate(dfs2[0:], start=2023):\n",
    "    coluna_nome = f'total_{i}'\n",
    "            \n",
    "    # Realizar o merge (junção) com base na coluna 'tipo_residuo\n",
    "    df = pd.merge(df, y[['tipo_residuo', coluna_nome]], on='tipo_residuo', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo os NaN dos números\n",
    "for ano in range(2013, 2025):\n",
    "    if ano != 2022:\n",
    "        df[f'total_{ano}'] = df[f'total_{ano}'].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletando a ultima linha que é tudo NaN\n",
    "df = df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando a coluna tipo_residuo\n",
    "\n",
    "df['tipo_residuo'] = df['tipo_residuo'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudando os nomes \n",
    "\n",
    "df['tipo_residuo'] = df['tipo_residuo'].replace({\n",
    "    'alim vencidos': 'alimentos_vencidos',\n",
    "    'desconsiderando escoria, chorume, cancelamentos e saï¿½das de resï¿½duos': 'nao_classificados',\n",
    "    'diversos-emae': 'diversos_emae',\n",
    "    'entulho apreendido': 'entulho_apreendido',\n",
    "    'entulho do predio': 'entulho_predial',\n",
    "    'entulho manual': 'entulho_manual',\n",
    "    'entulho mecanizado': 'entulho_mecanizado',\n",
    "    'equipe de eventos especiais e operacoes de emergencia': 'eventos_e_emergencias',\n",
    "    'feira livre': 'feira_livre',\n",
    "    'gg saude': 'saude_geral',\n",
    "    'limpeza urbana': 'limpeza_urbana',\n",
    "    'material apreendido': 'material_apreendido',\n",
    "    'patio compostagem': 'compostagem',\n",
    "    'pg saude': 'saude_publica',\n",
    "    'rejeito-cmt carolina maria de jesus': 'rejeitos_cmj', #repetido A\n",
    "    'rejeito-cmt cmj': ' rejeitos_cmj', #repetido A\n",
    "    'remocao residuos descartados': 'remocao_residuos', \n",
    "    'residuo de acumulador': 'acumuladores',\n",
    "    'residuo de desfazimento': 'desfazimentos',\n",
    "    'residuo ecoponto - entulho': 'ecoponto_entulho',\n",
    "    'residuos de boca de lobo': 'bocas_de_lobo',\n",
    "    'residuos de corregos': 'corregos',\n",
    "    'residuos de ecoponto': 'ecoponto',\n",
    "    'residuos de ecoponto - diversos': 'ecoponto_diversos',\n",
    "    'residuos de piscinao': 'piscinoes',\n",
    "    'residuos patio compostagem': 'patio_compostagem',\n",
    "    'seletiva': 'coleta_seletiva',\n",
    "    'varricao': 'varricao_manual',\n",
    "    'varricao mecanizada ': 'varricao_mecanizada',\n",
    "    'total geral' : 'total_geral'\n",
    "    \n",
    "})\n",
    "\n",
    "df['tipo_residuo'] = df['tipo_residuo'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somando as duplicadas para não perder os dados\n",
    "\n",
    "duplicadas = df[df.duplicated('tipo_residuo', keep=False)]\n",
    "df.loc[duplicadas.index, df.columns != 'tipo_residuo'] = duplicadas.groupby('tipo_residuo', sort=False).transform('sum').loc[duplicadas.index]\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deixando tudo com apenas 2 números depois do ponto\n",
    "for ano in range(2013,2025):\n",
    "    if ano != 2022:\n",
    "        df[f'total_{ano}'] = df[f'total_{ano}'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a linha 'total_gera\n",
    "\n",
    "df = pd.concat([df[df['tipo_residuo'] != 'total_geral'], df[df['tipo_residuo'] == 'total_geral']], ignore_index=True)\n",
    "\n",
    "colunas_para_somar = ['total_2013', 'total_2014', 'total_2015', 'total_2016', 'total_2017', 'total_2018', 'total_2019', 'total_2020']\n",
    "\n",
    "# Calcular a soma das colunas especificadas\n",
    "soma_colunas = df[colunas_para_somar].sum()\n",
    "\n",
    "# Atualizar os valores da linha \"total_geral\"\n",
    "df.loc[df['tipo_residuo'] == 'total_geral', colunas_para_somar] = soma_colunas.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando total_anos\n",
    "\n",
    "df['total_anos'] = df.iloc[:, 1:].select_dtypes(include='number').sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_2013    6219039.46\n",
      "total_2014    5888181.20\n",
      "total_2015    5750715.95\n",
      "total_2016    5452934.86\n",
      "total_2017    5620564.34\n",
      "total_2018    5688310.14\n",
      "total_2019      21835.95\n",
      "total_2020      25228.85\n",
      "total_2021    3421379.44\n",
      "total_2023    3452796.87\n",
      "total_2024    3515678.96\n",
      "Name: 35, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Salvar em excel\n",
    "\n",
    "# df.to_excel('tipo_residuos_total.xlsx', index=False)\n",
    "\n",
    "x = df.drop(columns=['total_anos']).select_dtypes(include='number').iloc[-1]\n",
    "df_soma = x.values\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
